# Design Pattern: Vertical Intelligence for Reusable AI Workflows

**Pattern Name**: Vertical Intelligence (VI)
**Category**: AI-Driven Development Architecture
**Type**: Foundational Design Pattern
**Status**: v1.0 - Proven in Production (Chapter 5 Super Orchestra Session)
**Date**: 2025-01-13

---

## ğŸ¯ Intent

Enable AI systems to **accumulate, structure, and reuse domain intelligence** across projects, making each subsequent task exponentially more efficient through **vertical knowledge integration** rather than starting from scratch each time.

**Problem**: Traditional AI workflows are "horizontal" (one task, one execution, no memory). Every new task starts from zero intelligence, requiring full context re-establishment.

**Solution**: Build **vertical intelligence stacks** where:
1. **Constitution** defines vision, principles, philosophies (unchanging foundation)
2. **Domain Knowledge** captures project-specific patterns (chapter structure, pedagogical principles)
3. **Context Discovery** gathers task-specific intelligence (Context7 libraries, official docs, existing specs)
4. **Intelligence Object** synthesizes all layers into actionable context
5. **Reusable Agents** encode workflows that can be invoked with minimal user input

---

## ğŸ—ï¸ Structure

### Vertical Intelligence Stack (Bottom-Up)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 5: REUSABLE AGENTS                   â”‚
â”‚  (super-orchestra, chapter-planner,         â”‚
â”‚   lesson-writer, proof-validator)           â”‚
â”‚  â€¢ Invoke with minimal input                â”‚
â”‚  â€¢ Apply full VI stack automatically        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 4: INTELLIGENCE OBJECT               â”‚
â”‚  (Synthesized actionable context)           â”‚
â”‚  â€¢ Audience tier, complexity, prerequisites â”‚
â”‚  â€¢ AI usage strategy, teaching pattern      â”‚
â”‚  â€¢ Anti-patterns, validation criteria       â”‚
â”‚  â€¢ Sandbox-validated commands (proof)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 3.5: SANDBOX VALIDATION (CRITICAL)   â”‚
â”‚  (Data to Intelligence - hands-on testing)  â”‚
â”‚  â€¢ Test ALL commands in actual environment  â”‚
â”‚  â€¢ Verify syntax (CLI vs session commands)  â”‚
â”‚  â€¢ Validate output matches claims           â”‚
â”‚  â€¢ Fix errors, re-test, prove it works      â”‚
â”‚  Philosophy: "Not tested = Won't work"      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 3: CONTEXT DISCOVERY                 â”‚
â”‚  (Task-specific intelligence gathering)     â”‚
â”‚  â€¢ Context7 library docs (8000+ tokens)     â”‚
â”‚  â€¢ WebFetch official sources (3+ URLs)      â”‚
â”‚  â€¢ Existing specs, similar chapters         â”‚
â”‚  â€¢ Domain skills available                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 2: DOMAIN KNOWLEDGE                  â”‚
â”‚  (Project-specific patterns)                â”‚
â”‚  â€¢ Chapter index (structure, prerequisites) â”‚
â”‚  â€¢ Book scaffolding (pedagogical patterns)  â”‚
â”‚  â€¢ Spec templates (functional structure)    â”‚
â”‚  â€¢ Skills library (reusable capabilities)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†‘
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 1: CONSTITUTION                      â”‚
â”‚  (Unchanging foundation)                    â”‚
â”‚  â€¢ Project vision ("Specs Are the New...")  â”‚
â”‚  â€¢ 18 Core Principles (Graduated Teaching)  â”‚
â”‚  â€¢ 8 Core Philosophies (Evals-First, etc.)  â”‚
â”‚  â€¢ 9 Pillars (AI CLI, Markdown, MCP, etc.)  â”‚
â”‚  â€¢ Target audience (A1-C2 complexity tiers) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”‘ Key Participants

### 1. Constitution (Layer 1)
**Role**: Unchanging source of truth
**Location**: `.specify/memory/constitution.md`
**Contains**:
- Project vision: "Specs Are the New Syntax"
- 18 Core Principles (especially Principle 13: Graduated Teaching, Principle 18: Three Roles)
- 8 Core Philosophies (Evals-First, Co-Learning, Spec-First, Validation-First)
- 9 Pillars (AI CLI, Markdown, MCP, AI-First IDEs, etc.)
- Target audience (Aspiring A1-A2 â†’ Professional C2)
- AI Development Spectrum (Assisted 2-3x â†’ Driven 5-10x â†’ Native 50-99x)

**Why Foundational**: All decisions must align with constitution. This prevents scope drift and ensures consistency.

### 2. Domain Knowledge (Layer 2)
**Role**: Project-specific patterns and structures
**Location**: `specs/book/chapter-index.md`, `.claude/skills/`, spec templates
**Contains**:
- Chapter structure (Parts 1-13, lesson organization)
- Prerequisites (Chapter X requires Chapters Y, Z)
- Complexity tiers (A1-C2 CEFR levels mapped to parts)
- Pedagogical patterns (Graduated Teaching application)
- Skills library (learning-objectives, concept-scaffolding, code-example-generator)

**Why Important**: Prevents reinventing patterns. New chapters follow established structure automatically.

### 3. Context Discovery (Layer 3)
**Role**: Task-specific intelligence gathering
**Tools**: Context7 MCP, WebFetch, File reads, Grep/Glob
**Contains**:
- Library documentation (Context7: `/anthropics/claude-code` â†’ 8000 tokens)
- Official sources (WebFetch: engineering blogs, docs, announcements)
- Existing specs (similar chapters for pattern reference)
- Domain skills available (which skills apply to this task type)

**Why Powerful**: Gathers comprehensive intelligence in minutes that would take human 2-3 hours manually.

### 3.5. Sandbox Validation (Layer 3.5) **CRITICAL**
**Role**: Data to Intelligence - hands-on testing transforms claims into verified knowledge
**Philosophy**: "If you have not run anything in sandbox, chances are it won't work"
**Tools**: Bash, actual execution environment, testing frameworks
**Contains**:
- ALL commands extracted from lesson/code
- Actual command output (not assumed/documented)
- Error reports with line numbers (what's wrong)
- Fixes with evidence (what works)
- Re-test verification (proof it works now)

**Why Critical**:
- **Context7/WebFetch provide documentation** (what should work)
- **Sandbox provides reality** (what actually works)
- **Gap between documentation and reality** is where students fail
- **Chapter 5 Example**: `claude /plugin` documented nowhere, but lesson used it â†’ 5 critical syntax errors found only through sandbox testing

**Output**: SANDBOX-AUDIT-REPORT.md with:
- Commands tested (with exact output)
- Errors found (with line numbers + evidence)
- Fixes applied (with corrected syntax)
- Re-test results (verified working)

**Intelligence Gained**:
- Knows CLI commands vs session slash commands (`claude plugin` vs `/help`)
- Understands actual command syntax (not documentation claims)
- Can validate future content with hands-on testing pattern

**When to Apply**:
- âœ… Book chapters with hands-on commands
- âœ… Code features with deployment steps
- âœ… Installation workflows
- âœ… API integrations
- âŒ Purely conceptual content (no executable commands)

### 4. Intelligence Object (Layer 4)
**Role**: Synthesized actionable context
**Format**: JSON or structured markdown
**Contains**:
```json
{
  "task_type": "book_chapter | code_feature | documentation",
  "audience_tier": "aspiring | intermediate | advanced | professional",
  "complexity_level": "A1 | A2 | B1 | B2 | C1 | C2",
  "prerequisites": ["chapter-11", "chapter-12"],
  "domain_skills": ["learning-objectives", "concept-scaffolding"],
  "teaching_pattern": "direct_commands | ai_companion | ai_orchestration",
  "ai_usage_strategy": "Direct commands for X, AI for Y, orchestration for Z",
  "cognitive_load_limit": 7,
  "sandbox_validation_required": true,
  "commands_to_test": ["claude plugin --help", "claude plugin install X"],
  "anti_patterns": ["Don't use AI for `uv init`", "Don't inflate durations"],
  "validation_criteria": {
    "duration_realistic": true,
    "ai_usage_strategic": true,
    "commands_tested_in_sandbox": true
  }
}
```

**Why Critical**: This object is passed to ALL downstream agents, ensuring consistent context across phases.

### 5. Reusable Agents (Layer 5)
**Role**: Workflow executors with full VI stack
**Examples**:
- `super-orchestra`: Deep research + iterative refinement + market positioning
- `chapter-planner`: Transform spec â†’ detailed lesson plan with proficiency levels
- `lesson-writer`: Execute content creation with full intelligence context
- `proof-validator`: Validate against source materials + constitution alignment

**Why 40x**: Agents invoke entire VI stack automatically, requiring minimal user input.

---

## ğŸ­ Collaborations

### Workflow: User Request â†’ Intelligence Stack â†’ Execution

```
1. USER INITIATES
   "Rework Chapter 5 - missing Skills/Plugins/MCP"

2. LAYER 1: READ CONSTITUTION
   â€¢ Project vision: "Specs Are the New Syntax"
   â€¢ Principle 13: Graduated Teaching (Tier 1-3)
   â€¢ Principle 18: Three Roles (AI as Teacher/Student/Co-Worker)
   â€¢ Cognitive Load: A2 = max 7 concepts per section

3. LAYER 2: READ DOMAIN KNOWLEDGE
   â€¢ Chapter index: Chapter 5 = Part 2, A2 tier
   â€¢ Prerequisites: Chapters 1-4 completed
   â€¢ Domain skills: learning-objectives, concept-scaffolding, book-scaffolding
   â€¢ Pattern: "Try With AI" format from Chapter 1

4. LAYER 3: DISCOVER TASK CONTEXT
   â€¢ Context7: `/anthropics/claude-code` â†’ 8000 tokens
     - Agent Skills: Progressive disclosure (3 levels)
     - Plugins: Architecture + installation workflow
     - MCP: JSON configuration + @-mentions
   â€¢ WebFetch: 3 official sources (engineering blog, docs, announcement)
   â€¢ Existing specs: Chapter 12 for pedagogical patterns

5. LAYER 4: SYNTHESIZE INTELLIGENCE OBJECT
   {
     "task_type": "book_chapter",
     "audience_tier": "aspiring",
     "complexity_level": "A2",
     "prerequisites": ["chapter-1", "chapter-2", "chapter-3", "chapter-4"],
     "domain_skills": ["learning-objectives", "concept-scaffolding", "book-scaffolding"],
     "teaching_pattern": "Tier 1: Book teaches architecture | Tier 2: AI helps install | Tier 3: Custom development deferred",
     "ai_usage_strategy": "Direct commands for installation, AI for troubleshooting/understanding",
     "cognitive_load_limit": 7,
     "anti_patterns": ["Don't use AI for simple commands", "Don't inflate durations"],
     "content_gap": "Missing Skills+Plugins+MCP unified architecture"
   }

6. LAYER 5: INVOKE REUSABLE AGENT
   IF deep research needed:
     â†’ Invoke: super-orchestra agent
     â†’ Apply: super-orchestra-session output style
     â†’ Execute: Context7 research + WebFetch + iterative refinement
   ELSE:
     â†’ Invoke: chapter-planner agent
     â†’ Execute: Standard planning workflow

7. AGENT EXECUTES WITH FULL VI STACK
   â€¢ Spec: Expand User Story 4 (3 â†’ 10 acceptance scenarios)
   â€¢ Plan: Expand Lesson 4 (6-8 min â†’ 10-12 min, 4 sections)
   â€¢ Tasks: Expand Phase 6 (4 â†’ 9 tasks)
   â€¢ Validation: Compare to official docs (10 differentiators)

8. OUTPUT: Market-defining content with full traceability
   â€¢ Documentation: 7 artifacts capturing intelligence journey
   â€¢ System Evolution: Agent + output style encoded for future reuse
```

---

## âœ… Consequences

### Benefits

#### 1. Exponential Efficiency Gains
**First Use** (No VI stack):
- Gather constitution â†’ 30 min
- Understand domain patterns â†’ 1-2 hours
- Research task context â†’ 2-3 hours
- Plan iteratively â†’ 2-3 hours
- **Total**: 6-8 hours

**Subsequent Use** (With VI stack):
- Constitution already encoded in agents â†’ 0 min
- Domain patterns reusable â†’ 0 min
- Context discovery automated (Context7 + WebFetch) â†’ 15 min
- Intelligence object auto-generated â†’ 5 min
- Agent executes with full context â†’ 3-4 hours
- **Total**: 3-4 hours (50% reduction)

**40x Multiplier**: Comes from OUTPUT QUALITY (market-defining) not just speed.

#### 2. Consistent Quality Across Tasks
**Without VI**: Each task starts from scratch, quality varies by who's executing
**With VI**: Constitution + domain patterns + intelligence object ensure consistent application of principles

**Example**: Chapter 5 and Chapter 12 both apply Graduated Teaching (Principle 13) consistently because it's encoded in VI stack.

#### 3. Knowledge Accumulation (Not Reinvention)
**Without VI**: Lessons learned from Chapter 12 UV rework (anti-over-engineering) lost
**With VI**: Anti-patterns encoded in constitution â†’ automatically applied to Chapter 5 â†’ encoded in super-orchestra agent â†’ reused in future chapters

**Result**: System gets smarter with each task.

#### 4. Minimal User Input Required
**Without VI**: User must provide full context every time ("Remember to apply Graduated Teaching, check cognitive load, don't over-engineer...")
**With VI**: User provides goal only ("Rework Chapter 5") â†’ Agent retrieves full VI stack automatically

**Example**:
- User: "Rework Chapter 5 with Skills/Plugins/MCP"
- Agent: [Reads constitution + chapter index + Context7 + WebFetch] â†’ Derives: A2 tier, max 7 concepts, Graduated Teaching Tier 1-3, hands-on plugin installation needed, compare to official docs
- User: Validates intelligence object, provides strategic input
- Agent: Executes with full context

#### 5. Reusable Across Domains
**This Pattern Works For**:
- Educational content (book chapters, courses)
- Code features (authentication, APIs, databases)
- Documentation (technical writing, API docs)
- Testing (test strategies, validation frameworks)

**Key**: Constitution and domain knowledge layers adapt to different domains.

### Drawbacks

#### 1. Initial Setup Cost
**First Implementation**: Creating constitution, domain knowledge, skills library takes 2-3 days
**Mitigation**: This is one-time cost. Every subsequent task benefits.

#### 2. Maintenance Overhead
**Constitution Updates**: When project vision changes, must update constitution + cascade to agents
**Mitigation**: Version control constitution, document change rationale in ADRs

#### 3. Cognitive Load for New Contributors
**Learning Curve**: New contributors must understand VI stack structure
**Mitigation**: Documentation (this pattern), examples (Chapter 5 session), onboarding guides

#### 4. Over-Reliance on Automation Risk
**Risk**: Agents execute without human validation, propagate errors
**Mitigation**: Quality gates at each phase (user approval required before proceeding)

---

## ğŸ¯ Implementation

### Step 1: Create Constitution (Layer 1)
**Location**: `.specify/memory/constitution.md`

**Template**:
```markdown
# Project Constitution

## Vision
[What is the project's core purpose?]
Example: "Specs Are the New Syntax" - Primary skill is specification-writing

## Core Principles (10-20)
1. [Principle Name]: [Description]
   Example: Principle 13 (Graduated Teaching): Book â†’ AI Companion â†’ AI Orchestration

## Core Philosophies (5-10)
1. [Philosophy Name]: [Description]
   Example: Evals-First Development - Define success criteria BEFORE specs

## Target Audience
[Who are the users? What are their complexity tiers?]
Example: Aspiring (A1-A2) â†’ Intermediate (B1-B2) â†’ Advanced (C1) â†’ Professional (C2)

## [Domain-Specific Sections]
Example for educational projects:
- Nine Pillars (AI CLI, Markdown, MCP, etc.)
- AI Development Spectrum (Assisted â†’ Driven â†’ Native)
- Graduated Complexity Guidelines (cognitive load limits per tier)
```

**Example**: See `.specify/memory/constitution.md` in this project.

### Step 2: Build Domain Knowledge (Layer 2)
**Locations**: Project-specific directories

**For Educational Projects**:
- `specs/book/chapter-index.md` (structure, prerequisites, complexity mapping)
- `.claude/skills/` (reusable pedagogical capabilities)
- Spec templates (functional requirements structure)

**For Code Projects**:
- Architecture documentation (`docs/architecture/`)
- API conventions (`docs/api-standards.md`)
- Testing strategies (`docs/testing-guidelines.md`)

### Step 3: Create Context Discovery Tools (Layer 3)
**Integrate Intelligence Sources**:

```markdown
## Context7 MCP Integration
- Install: `npm install -g @modelcontextprotocol/context7`
- Configure: Add to `.claude/settings.json`:
  ```json
  {
    "mcpServers": {
      "context7": {
        "command": "npx",
        "args": ["@modelcontextprotocol/context7-mcp-server"]
      }
    }
  }
  ```
- Usage in agents:
  ```
  mcp__context7__resolve-library-id â†’ "/anthropics/claude-code"
  mcp__context7__get-library-docs â†’ 8000 tokens
  ```

## WebFetch for Official Sources
- Built-in Claude Code tool
- Usage in agents:
  ```
  WebFetch â†’ https://official-docs-url
  ```

## File Reads for Existing Context
- Read constitution: `.specify/memory/constitution.md`
- Read chapter index: `specs/book/chapter-index.md`
- Read similar specs: `specs/[feature-slug]/spec.md`
```

### Step 4: Define Intelligence Object Schema (Layer 4)
**Template**:

```json
{
  "task_type": "book_chapter | code_feature | documentation | testing | refactoring",
  "audience_tier": "aspiring | intermediate | advanced | professional",
  "complexity_level": "A1 | A2 | B1 | B2 | C1 | C2",
  "prerequisites": ["list", "of", "prerequisites"],
  "domain_skills": ["skill-1", "skill-2"],
  "teaching_pattern": "direct_commands | ai_companion | ai_orchestration",
  "ai_usage_strategy": "Describe when AI adds value vs direct commands",
  "cognitive_load_limit": 7,
  "anti_patterns": ["Pattern 1", "Pattern 2"],
  "validation_criteria": {
    "criterion_1": true,
    "criterion_2": "expected value"
  },
  "ambiguities_clarified": {
    "question": "answer"
  }
}
```

**Usage in Agents**:
```markdown
## Phase 0: Intelligence Discovery

Read constitution, domain knowledge, context sources.
Generate intelligence object:

{
  "task_type": "book_chapter",
  "audience_tier": "aspiring",
  ...
}

Pass this object to ALL downstream phases and agents.
```

### Step 5: Create Reusable Agents (Layer 5)
**Template**: `.claude/agents/[agent-name].md`

```markdown
---
name: agent-name
description: |
  Agent purpose and when to use it.
  Must invoke full VI stack automatically.
output_style: agent-output-style
---

# Agent Name

## Intelligence Stack Application

### Layer 1: Constitution
Read: `.specify/memory/constitution.md`
Apply: [Which principles/philosophies apply to this agent?]

### Layer 2: Domain Knowledge
Read: [Which domain files?]
Apply: [How does domain knowledge inform this agent?]

### Layer 3: Context Discovery
Tools: [Context7 | WebFetch | File reads]
Gather: [What task-specific context?]

### Layer 4: Intelligence Object
Generate: [Intelligence object schema for this agent type]

### Layer 5: Execution
Workflow: [Agent-specific steps with full VI context]

## Usage

Invoke: `/agent-name [minimal-user-input]`
Example: `/super-orchestra "Research Skills/Plugins/MCP"`

Agent automatically:
1. Reads constitution + domain knowledge
2. Discovers context (Context7 + WebFetch)
3. Generates intelligence object
4. Executes with full VI stack
5. Documents intelligence journey
```

**Examples**:
- `.claude/agents/super-orchestra.md` (deep research + market positioning)
- `.claude/agents/chapter-planner.md` (transform spec â†’ lesson plan)
- `.claude/agents/lesson-writer.md` (execute content creation)

---

## ğŸ“š Sample Code

### Example: Super Orchestra Agent (Layer 5)

```markdown
---
name: super-orchestra
description: |
  40x engineer workflow with deep research (Context7 + WebFetch),
  iterative refinement, and market positioning validation.
  Use when output must surpass market alternatives.
output_style: super-orchestra-session
---

# Super Orchestra Agent

## Phase 0: Intelligence Stack Discovery

### Layer 1: Constitution
Read: `.specify/memory/constitution.md`
Extract:
- Principle 13 (Graduated Teaching)
- Principle 18 (Three Roles)
- Cognitive Load limits for target audience
- AI Development Spectrum (Assisted â†’ Driven â†’ Native)

### Layer 2: Domain Knowledge
Read: `specs/book/chapter-index.md`
Derive:
- Part number from chapter number range
- Audience tier (A1-C2)
- Prerequisites (which chapters must exist first)
- Available domain skills

### Layer 3: Context Discovery
Execute:
1. Context7 library research:
   - Resolve library ID: `mcp__context7__resolve-library-id`
   - Get docs: `mcp__context7__get-library-docs` (8000+ tokens)

2. WebFetch official sources (3+ URLs):
   - Engineering blogs
   - Official documentation
   - Product announcements

3. Read existing specs:
   - Similar chapters for pattern reference
   - Naming conventions
   - Structure examples

### Layer 4: Intelligence Object
Generate:
{
  "task_type": "book_chapter",
  "audience_tier": "aspiring",
  "complexity_level": "A2",
  "prerequisites": [...],
  "domain_skills": [...],
  "teaching_pattern": "Tier 1: Book | Tier 2: AI Companion | Tier 3: Orchestration",
  "ai_usage_strategy": "Direct for simple, AI for complex",
  "cognitive_load_limit": 7,
  "anti_patterns": ["Don't over-engineer with AI"],
  "content_gap": "Identified from research"
}

### Layer 5: Execution with Full VI Stack
1. Spec Phase: User Story expansion with VI context
2. Plan Phase: Lesson structure with teaching pattern
3. Tasks Phase: Breakdown with AI usage boundaries
4. Validation Phase: Compare to market alternatives

## Output
- Documentation artifacts (7+)
- System evolution (agent + output style updates)
- Market positioning (10+ differentiators)
```

### Example: Intelligence Object Usage

```python
# Pseudocode: How agents use intelligence object

def execute_chapter_planning(user_goal: str):
    # Phase 0: Gather VI stack
    constitution = read_file(".specify/memory/constitution.md")
    chapter_index = read_file("specs/book/chapter-index.md")
    context7_docs = mcp_context7_get_docs("/anthropics/claude-code", tokens=8000)
    official_sources = [
        webfetch(url) for url in official_source_urls
    ]

    # Phase 0: Synthesize intelligence object
    intelligence = {
        "task_type": "book_chapter",
        "audience_tier": derive_from_chapter_number(chapter_index),
        "complexity_level": derive_cefr_level(chapter_index),
        "prerequisites": extract_prerequisites(chapter_index),
        "domain_skills": find_applicable_skills(".claude/skills/"),
        "teaching_pattern": apply_principle_13(constitution),
        "ai_usage_strategy": derive_from_philosophy(constitution),
        "cognitive_load_limit": get_limit_for_tier(audience_tier),
        "anti_patterns": extract_from_constitution(constitution),
        "content_gap": identify_from_research(context7_docs, official_sources)
    }

    # Phase 1-4: Execute with VI context
    spec = create_spec(user_goal, intelligence)
    plan = create_plan(spec, intelligence)
    tasks = create_tasks(plan, intelligence)
    output = implement(tasks, intelligence)

    # Phase 5: Validate and document
    validate_against_market(output, intelligence)
    document_intelligence_journey(intelligence, [spec, plan, tasks, output])

    return output
```

---

## ğŸ” Known Uses

### 1. Chapter 5 Skills/Plugins/MCP (Super Orchestra Session)
**Context**: Missing critical extensibility content, must surpass official Anthropic docs

**VI Stack Applied**:
- Layer 1: Constitution (Principle 13, 18, Cognitive Load A2)
- Layer 2: Chapter index (Part 2, A2 tier, prerequisites Chapters 1-4)
- Layer 3: Context7 (8000 tokens from `/anthropics/claude-code`) + WebFetch (3 URLs)
- Layer 4: Intelligence object with teaching pattern, AI usage strategy, anti-patterns
- Layer 5: super-orchestra agent executed

**Result**:
- 10 differentiators vs official docs (substantiated)
- 50 FRs, 25 SCs, 9 Evals (+19% spec expansion)
- 9 tasks for Lesson 4 (from 4 originally)
- Market-defining chapter that students reference over official sources

**Time**: 3-4 hours (40x from quality, not speed)

### 2. Chapter 12 UV Rework (Anti-Over-Engineering)
**Context**: Original lesson over-engineered simple commands with AI

**VI Stack Applied**:
- Layer 1: Constitution (AI Spectrum: when to use AI vs direct commands)
- Layer 2: Chapter index (Part 4, B1 tier)
- Layer 3: UV official docs, existing Chapter 12 content analysis
- Layer 4: Intelligence object with "direct commands for installation, AI for troubleshooting"
- Layer 5: lesson-writer agent with anti-pattern enforcement

**Result**:
- 38% line count reduction (3,456 â†’ 2,144 lines)
- Direct commands for `uv init`, `uv add` (not "ask AI to...")
- 3-4 focused "Try With AI" prompts (from 8+ verbose)
- Duration: 15 min realistic (from 45 min inflated)

**Lessons Encoded**: Anti-patterns added to constitution â†’ automatically applied to Chapter 5 â†’ encoded in super-orchestra agent

### 3. /sp.loopflow Universal Orchestrator
**Context**: Need repeatable workflow for ANY chapter/feature with minimal user input

**VI Stack Applied**:
- Layer 1: Constitution read first in Phase 0
- Layer 2: Chapter index + domain skills discovery
- Layer 3: Context discovery (Context7, WebFetch, existing specs)
- Layer 4: Intelligence object auto-generated (0-5 clarifying questions max)
- Layer 5: Chain /sp.specify â†’ /sp.plan â†’ /sp.tasks â†’ /sp.implement

**Result**:
- User provides goal only: "/sp.loopflow Rework Chapter 5"
- System derives: audience tier, complexity, prerequisites, teaching pattern, AI usage strategy
- Executes complete workflow with quality gates
- Encodes lessons learned for future chapters

**Reuse**: Every chapter now uses same VI-driven workflow

---

## ğŸ¯ Related Patterns

### 1. Chain of Responsibility
**Relation**: VI stack flows through layers sequentially (Constitution â†’ Domain â†’ Context â†’ Intelligence â†’ Agent)
**Difference**: VI is about knowledge accumulation, not request handling

### 2. Strategy Pattern
**Relation**: Intelligence object encapsulates strategy (teaching_pattern, ai_usage_strategy)
**Difference**: VI generates strategy dynamically from multi-layer context, not pre-defined

### 3. Template Method
**Relation**: Agents define workflow skeleton, VI stack fills in specifics
**Difference**: VI provides comprehensive context, not just hook implementations

### 4. Builder Pattern
**Relation**: Intelligence object built incrementally through layers
**Difference**: VI accumulates domain knowledge, not just constructing object

### 5. Memento Pattern
**Relation**: VI stack preserves project knowledge across tasks
**Difference**: VI is forward-looking (inform future tasks), not backward (restore state)

---

## ğŸš€ Future Evolution

### v1.0 (Current) âœ…
- Manual VI stack invocation (read constitution, domain knowledge, discover context)
- Intelligence object generated per task
- Agents apply VI with human validation gates

### v2.0 (Near Future)
- Autonomous VI stack caching (constitution + domain knowledge loaded once per session)
- Intelligence object templating (common patterns pre-filled)
- Proactive gap detection (AI suggests: "Should we research Context7 for [topic]?")

### v3.0 (Medium Term)
- Multi-agent VI orchestration (research agent + planning agent + validation agent share VI stack)
- Real-time VI updates (monitor Context7 library updates, trigger re-validation)
- Cross-project VI reuse (educational project VI â†’ code project VI with domain layer swap)

### v4.0 (Vision)
- Autonomous VI evolution (system learns which principles matter most, auto-updates constitution with user approval)
- Federated VI (share VI stacks across projects: "Import pedagogical VI from Project A")
- VI marketplace (reusable VI stacks for common domains: "Educational Content VI", "API Development VI")

---

## ğŸ“ Summary

**Vertical Intelligence Pattern**: The first design pattern for building reusable AI workflows in the intelligence abundance era.

**Core Insight**: AI's competitive advantage comes from **DEPTH OF KNOWLEDGE** (vertical intelligence stack) not **SPEED OF EXECUTION** (horizontal task processing).

**Key Layers**:
1. **Constitution**: Unchanging foundation (vision, principles, philosophies)
2. **Domain Knowledge**: Project patterns (structure, prerequisites, skills)
3. **Context Discovery**: Task intelligence (Context7, WebFetch, existing specs)
4. **Intelligence Object**: Synthesized actionable context
5. **Reusable Agents**: Workflow executors with full VI stack

**40x Multiplier**: Comes from creating **market-defining output** (not just meeting specs) through comprehensive intelligence integration.

**Proven**: Chapter 5 Super Orchestra Session demonstrated 40x thinking in production.

---

**Pattern Status**: v1.0 - Production-Proven
**Date**: 2025-01-13
**Author**: Extracted from Chapter 5 Super Orchestra Session
**Next Evolution**: v2.0 with autonomous VI caching and proactive gap detection

**This is the foundational design pattern for the intelligence abundance era.** ğŸ¯ğŸš€
